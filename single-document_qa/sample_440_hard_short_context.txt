DMesh: A Differentiable Representation for
General Meshes
Sanghyun Son1, Matheus Gadelha2, Yang Zhou2, Zexiang Xu2,
Ming C. Lin1, and Yi Zhou2
1 University of Maryland, College Park
2 Adobe Research
Fig. 1: (→) Optimization process. We can start from either random state (up) or
initialization based on sample points (down) for faster convergence. Mesh connectivity
changes dynamically during the optimization. To make this topology change possible,
we compute existence probability for an arbitrary set of faces in a differentiable manner.
Abstract. We present a differentiable representation, DMesh, for gen-
eral 3D triangular meshes. DMesh considers both the geometry and
connectivity information of a mesh. In our design, we first get a set
of convex tetrahedra that compactly tessellates the domain based on
Weighted Delaunay Triangulation (WDT), and formulate probability of
faces to exist on our desired mesh in a differentiable manner based on
the WDT. This enables DMesh to represent meshes of various topol-
ogy in a differentiable way, and allows us to reconstruct the mesh under
various observations, such as point cloud and multi-view images using
gradient-based optimization. The source code and full paper is available
at: https://sonsang.github.io/dmesh-project 3.
Keywords: Differentiable Mesh · 3D reconstruction
3 This paper was last modified at Apr 9, 2024


2
S. Son et al.
1
Introduction
Polygonal meshes are widely used in modeling and animation due to their di-
verse, compact and explicit configuration. Recent AI progress has spurred ef-
forts to integrate mesh generation into machine learning, but challenges like
varying topology hinder suitable differentiable mesh representations. This limi-
tation leads to reliance on differentiable intermediates like implicit functions, and
subsequent iso-surface extraction for mesh creation [16,25,36,43,44]. However,
meshes generated by such approaches can be unnecessarily dense and misaligned
at sharp regions [44], and struggle with open surfaces due to their reliance on
the volumetric representation.
The fundamental challenge in creating a differentiable mesh representation
lies in formulating both the vertices’ geometric features and their connectiv-
ity, defined as edges and faces in a differentiable way. Given a vertex set, pre-
dicting their connectivity in a free-form way using existing machine learning
data-structures can cost significant amount of computation and be difficult to
avoid irregular and intersecting faces. Consequently, most studies on differen-
tiable meshes simplify the task by using a mesh with a pre-determined topology
and modifying it through various operations [17, 38, 40, 54]. This work, on the
contrary, ambitiously aims to establish a general 3D mesh representation, named
as DMesh, where both mesh topology and geometric features (e.g. encoded in
vertex location) can be simultaneously optimized through gradient-based tech-
niques.
Our core insight is to use differentiable Weighted Delaunay Triangulation
(WDT) to divide a convex domain, akin to amber encapsulating a surface mesh,
into tetrahedra to form a mesh. To create a mesh with arbitrary topology, we
select only a subset of triangular faces from the tetrahedra, termed the “real
part", as our final mesh. The other faces, the “imaginary part", support the
real part but are not part of the final mesh. We introduce a method to assess
the probability of a face being part of the mesh based on weighted points that
carry positional and inclusiveness information. Optimization is then focused on
the points’ features, using a dual power diagram of WDT [3] to generate the
triangular mesh. The probability determination allows us to compute geometric
losses and rendering losses during gradient-based optimization. This method is
essentially a 3D, differentiable extension of A-shape [33,34], and a differentiable
solution to the problem addressed by constrained Delaunay Triangulation [15,
45,46].
The key contributions of our work can be summarized as follows.
– We present a novel mesh representation, DMesh, which is versatile to ac-
commodate various mesh types for both open surfaces and closed surfaces.
The generated meshes are always face-intersection-free.
– We provide efficient reconstruction algorithms for DMesh, which are designed
for 3d point cloud and multi-view image inputs. For multi-view reconstruc-
tion, we present a differentiable renderer that meets our needs.
– We provide effective regularization methods for DMesh, which can be used
for mesh simplification, or triangle quality enhancement.


DMesh: A Differentiable Representation for General Meshes
3
Fig. 2: Our overall framework to optimize mesh according to the given observations.
(a): Each point is defined by a 5-dimensional feature vector, which includes position,
weight, and real value. Points with larger real values are rendered in red. (b): Given
a set of points, we can gather possible faces to exist in our mesh and evaluate their
existence probability in differentiable manner. (c): We can compute reconstruction loss
by comparing our mesh with given observations, such as mesh, point cloud, or multi-
view images. (d): To facilitate the optimization process and enhance the mesh quality,
we can use additional regularizations.
– To overcome prohibitively large computational cost of the exact formulation,
we propose an efficient relaxation that computes the face existence proba-
bilities with a practical computational cost.
Additionally, to further accelerate the algorithm, we implemented our main
algorithm and differentiable renderer in CUDA, which is made available for fur-
ther research.
2
Related Work
2.1
Shape Representations for Optimization
Neural Implicit Functions The trend of modeling 3D objects as differentiable
neural representations has gained popularity in graphics and vision applications,
primarily for 3D reconstruction and novel view synthesis, allowing shape opti-
mization through gradient descent and backpropagation [7, 8, 26, 35, 47, 51, 52].
Many methods, inspired by NeRF [35], express scene geometry using volume
density and differentiable volume rendering. However, these density-based vol-
umetric approaches don’t always result in accurate 3D geometry. To improve
this, several approaches [39,47,48,50] model surface functions as neural signed
distance functions (SDFs), converting them to density for rendering and opti-
mization. More recently, neural unsigned distance functions (UDFs) have been
developed to model open surfaces, which SDFs can’t describe [28, 29]. While
these implicit surface representations show promise in reconstruction, they re-
quire iso-surface extraction algorithms like Marching Cubes [30] to convert im-
plicit functions to explicit high-poly meshes, introducing geometric errors. In
contrast, our explicit representation can directly output a mesh that can also
represent open surfaces, avoiding these issues.


4
S. Son et al.
Mesh Representations Previous methods have tried optimizing meshes di-
rectly, but often with the assumption of a fixed overall mesh topology [9, 23,
27,38]. While local connectivity can be altered through remeshing [40], the fun-
damental geometric topology remains unchanged. Learning-based approaches
like BSP-Net [11] allow for topological variation, yet their meshing process
isn’t differentiable. Recently, differentiable iso-surface extraction techniques have
been developed, resulting in high-quality geometry reconstruction of various
topology when combined with Neural or discrete Signed Distance Functions
(SDFs) [25,36,43,44,49]. Some methods even demonstrate backpropagating gra-
dients from mesh vertices to SDF values using non-differentiable techniques like
Marching Cubes [32]. However, these surface extraction methods, reliant on SDFs
and uniform grids, often need high-poly meshes for accurate reconstruction, re-
gardless of the actual surface’s complexity. Our approach does not have to con-
cern about these issues, because we explicitly define faces and their existence
probabilities. See Table 3 for more detailed comparisons to these other methods.
2.2
Shape Representation using Delaunay Triangulation
Delaunay Triangulation (DT) in Rd connects points whose Voronoi cells share a
boundary [3], making it useful for reconstructing shapes from unorganized point
sets. It’s been shown that DT of dense samples on a smooth 2D curve includes
the curve within its edges [1,5]. This idea of using DT to approximate shape has
been successfully extended to 3D, to reconstruct three-dimensional shapes [2]
for point sets that satisfy certain constraints. Our method can be thought of as
a differentiable version of these approaches.
Additionally, [42] focused on this DT’s property to connect points and tes-
sellate the domain, and proposed a differentiable WDT algorithm to compute
smooth inclusion, or existence score of 2-simplexes (triangles) in 2 dimensional
WDT. Our approach develops this approach to compute that score for 2-simplexes
in 3 dimensional WDT, which faces different computational challenges than the
previous work (Section 3.3). More recently, VoroMesh [31] used similar approach
to ours using Voronoi diagram for point cloud reconstruction, but it cannot han-
dle open surfaces and is only confined to point clouds (Section 4).
3
Formulation
In this section, we start with the definition of our new mesh representation. Then
we introduce its differentiable formulation, which evaluates the probability of a
face to exist in the mesh. Finally we explain how to conquer the computational
difficulties posed in our formulation.
3.1
Overall definition
In this work, we take a flexible approach to define a d-dimensional mesh as a
set of (d −1)-simplexes 4, and propose to represent a mesh as a subset
4 They become line segments when d = 2, and triangles when d = 3.


DMesh: A Differentiable Representation for General Meshes
5
(a) 2D Font
(b) 3D Dragon
Fig. 3: Illustration of our mesh representation for 2D and 3D cases. (a): Our represen-
tation in 2D for a letter “A”. (b): Our representation in 3D for a dragon model. Blue
faces are “real part” and yellow ones are “imaginary part”.
of WDT. To elaborate, for a given set of d-dimensional points P ∈Rd and
their weights W ∈R, we first obtain the WDT from the weighted points, which
tessellates the convex hull of the given points into a compact set of d-simplexes.
Then, we extract the desirable (d −1)-simplexes from the tessellation to define
our mesh. Without losing generality, we call the (d −1)-simplexes as faces here.
Among the entire set of faces, we refer the desirable faces as “real part”, and the
others as “imaginary part”. Figure 3 illustrates the cases for d = 2 and d = 3.
Note that the imaginary part is used to sustain the tessellation, even though it
is not included in the mesh.
Now let us assume there is a face F that we want to know if it exists in
the final mesh or not. Based on the above scheme, we notice that there are two
layers of “existence” for F. First, we have to check if F exists in the WDT or
not. Formally, we say F ∈WDT(P, W) if there is a d-simplex in the tessellation
induced by WDT that has F as one of its faces. Second, if F exists in WDT,
we have to find out if it is included in the “real part”. Therefore, we define two
predicates, Iwdt and Ireal, to evaluate the existence of F in the mesh.
 w\math b
b {I } _ {wdt}( F)
 &= \
left \{ \
be gi n  {arr ay}{ r c l} 1 &  \
m box {if} & F \in \text {WDT}(\mathbb {P},\mathbb {W}) \\ 0 & \mbox {else} & \end {array}\right . \\ \mathbb {I}_{real}(F) &= \left \{ \begin {array}{rcl} 1 & \mbox {if} & F \in \text {Mesh when } F \in \text {WDT}(\mathbb {P},\mathbb {W}) \\ 0 & \mbox {else} & \end {array}\right .
Unlike Iwdt, there are various formulations we can use for Ireal. In this work,
we opt to formulate it using point-wise value Ψ ∈{0, 1} for the convenience
of inference and optimization. When d = 3, given a face F = (pi, pj, pk) in
WDT(P, W), we define Ireal(F) as:
  \mathb b  {I}_{r eal }(F) = \min (\Psi _i,\Psi _j,\Psi _k) .
Note that all of the three points should have a value of 1 to make F to be
considered in the “real part”. Finally, we can define the complete face existence
function to determine if a face F exists in the final mesh or not as
  \m a thbb {I } (F) = \mathbb {I}_{wdt}(F) \wedge \mathbb {I}_{dist}(F).


6
S. Son et al.
Differentiable Approach To evaluate the existence of a face F in a differen-
tiable manner, we take a probabilistic approach. That is, we define differentiable
functions Λwdt and Λreal that evaluate the following probabilities,
 w\Lamb d a _ { wdt}(F ) &
= P
(F \in W D T(\ m athb b  { P}, \m athbb {W}))\label {eq:prob-wdt} \\ \Lambda _{real}(F) &= P(F \in \text {Mesh} \,|\, F \in WDT(\mathbb {P}, \mathbb {W})), \label {eq:prob-real}
(2)
which produce the following function to determine the final probability of F
to exist in mesh:
  \L a mbd a  (F) =  P(F \i n  Mesh) = \Lambda _{wdt}(F) \cdot \Lambda _{real}(F).
Not only this probabilistic interpretation is important to our differentiable
formulation, but also to the downstream tasks that we solve (Section 3.4). In
the following section, we discuss the details of Λwdt and Λreal.
Point Features Before moving on to the next section, we’d like to point out
that the introduced face existence solely depends on the configuration of the
weighted points. Thus, our representation features can be defined purely on the
point set. In our representation, each point is defined as a (d + 2)-dimensional
vector, d of which represents the spatial position, 1 stands for the weight for
WDT, and the remaining 1 is used as ψ, which corresponds to the differentiable
version of Ψ (Section 3.2). Note that we set the range of weight and ψ to be [0, 1]
in all of our experiments. Our overall framework to optimize our mesh according
to the given observations based on these point features is shown in Figure 2.
3.2
Probability Functions
Λwdt estimates probability of a face F to exist in WDT (Eq. 1). Our formulation
leverages the dual structure of WDT, or Power Diagram (PD) to compute it,
following [42]. Note that we develop our theoretical reasoning mainly in 2D for
ease of understanding, but it can be extended to 3D easily. To avoid confusion,
we denote 1-simplex (line segment) and 2-simplex (triangle) as F2 and F3 in this
section. Please see Appendix 7 for more detailed discussions.
To start with, given a set of points P ∈R2 and their weights W ∈R, we call
Power cell of pi in the (dual) PD as Ci. In Figure 4(a), we can see points p1, p2,
and p3 and their corresponding C1, C2, and C3 in PD. In Figure 4(b, d), C1 is
marked with orange lines. Now, we consider a face F2, which connects two points
pi and pj. Then we can construct its dual line LF in PD as the intersection of
two half spaces defined by the two points. In Figure 4, faces and their dual lines
are rendered as solid and dotted blue lines, respectively. In Figure 4(b, d), we
can observe that F2 exists if and only if the two Power cells Ci and Cj share a
common edge, and it is a subset of LF , which holds in general.
Based on this observation, we can measure the unsigned minimum distance
between LF and Power cells Ci and Cj, and use it to identify the existence of
F2. However, note that the distance stays at 0 when F2 exists, which means that


DMesh: A Differentiable Representation for General Meshes
7
Fig. 4: To compute probability of a (d−1)-simplex F’s existence in WDT (upper row),
we investigate its dual PD (lower row). For given F (solid blue), we measure the signed
distance δ (red) between its dual LF (dotted blue) and reduced Power cell (orange) for
the estimation. If F exists as shown in (b) and (c), δ becomes positive. In contrast, it
evaluates to negative when F does not exist as shown in (d) and (e).
we cannot measure how “stable” F2 is when it exists. Thus, it is not suitable for
measuring differentiable existence probability of F2.
To amend this issue, we adopt the concept of reduced Power cell [42]. Reduced
Power cell, denoted as RF |i, is a Power cell of pi when ignoring the other point
pj in F2. In Figure 4(c, e), we render reduced Power cell RF |1 for two different
F2s in orange lines. Note that when F2 exists, RF |1 gets bigger than C1 and LF
goes through it, rather than lying on its boundary. When F2 does not exist, RF |1
is just same as C1, and thus LF does not have contact with it.
Now, we newly define a signed distance between LF and RF |i. To that end,
we define a signed distance between a random point P ∈R2 and a random
reduced Power cell R as follows,
  \ta u _ {1}( P,  R) = d(P,  R) \cdot {(-1)}^{1 - I(P \in R)},
where d(P, R) is the minimum (unsigned) distance between P and R, and I(·)
is an indicator function. Then, based on τ1, we can define a signed distance
between a random line L and R as
  \la be l  {e
q :d elta_ line} \tau _{2}(L, R) = \max _{P \in L}\tau _{1}(P, R).
(3)
Observe that the sign of τ2 is positive when L goes through R, and negative
when L does not have contact with R.
Noting that RF |i can exist only when Ci exists 5, we define the signed distance
between the dual line LF and a reduced Power cell RF |i as
  \l a be l { e
q:delt a _l ine _r edu
ce d} \delta (L_F, R_{F|i}) = \left \{ \begin {array}{rcl} \tau _{2}(L_F, R_{F|i}) & \mbox {if} & \exists C_{i} \\ -\infty & \mbox {else} & \end {array}\right .
(4)
5 If the weight of pi is lower than its neighboring points, there is a chance that Ci
does not exist.


8
S. Son et al.
Then, the following relationship holds,
  \d e lt a ( L _ F ,wR_{F| i }) > 0 \Leftrightarrow \mathbb {I}_{wdt}(F) = 1.
which means, when F exists in WDT, its dual line has positive signed distance to
the reduced Power cell of its two ends, and vice versa. Note that this relationship
holds for any x ∈{i, j}, because the sign of every δ(LF , RF |x) is the same. In
the right columns of Figure 4(b, c), we can see pink line segments that represent
δ(LF , RF |1).
Then, coming back to d = 3, we define a function
  \la b e
l {eq: D el ta_ f ace}  \D elt a  (F_ 3 ) = \frac {1}{3}(\delta (L_{F}, R_{F|i}) + \delta (L_{F}, R_{F|j}) + \delta (L_{F}, R_{F|k})),
(5)
which satisfies ∆(F3) > 0 ⇔Iwdt(F) = 1, because the sign of every δ is the
same.
Note that this function goes to −∞if any one of the points in F3 loses its
Power cell. When all of the three points have Power cell, but F3 does not exists,
the function evaluates to a negative value. Finally, it becomes a positive value
when F3 exists. Therefore, we can define a differentiable probability function for
the face F3 to exist in WDT as follows,
 w\label  {eq:La m bda_face} \Lambda _{wdt}(F_3) &= \sigma (\alpha _{wdt} \cdot \Delta (F_3)),
(6)
where σ is a sigmoid function parameterized by αwdt. In our experiments, we set
αwdt = 1000.
Λreal evaluates the existence probability of F3 = {pi, pj, pk} in our mesh when
it exists in WDT. To define it, we modify per-point discrete value Ψ to ψ, which
can have a continuous value in [0, 1]. Then, we define Λreal as,
  \Lambda  _{real}( F_{ 3})  = \text {\textit {dmin}}(\psi _{i}, \psi _{j}, \psi _{k}, \alpha _{real}),
where dmin is a differentiable min operator (Appendix 7), and αreal is a
hyperparameter for it. We set it as αreal = 100 in our experiments.
3.3
Computational Difficulties
Although Eq. 4 plays a vital role, it is not trivial to compute it, especially in
3-dimensional space that we are dealing with. For instance, when Ci exists and
we have to evaluate Eq. 3, it is not trivial to find an answer to the optimization
problem. Moreover, it is hardly possible to compute every reduced Power cell,
RF |i,j,k, for every possible F3.
To overcome these computational difficulties, we propose to leverage lower
bound of Eq. 4, which can be efficiently found without constructing any reduced
Power cell explicitly. To that end, we treat two cases, F3 ∈WDT(P) and F3 /
∈
WDT(P), differently. To be specific, when F3 ∈WDT(P), we define δ1 as
  \la b el  {e q :delta_l in e_1 }  \delta _{1}(L_{F}, R_{F|i}) = \tau _{1}(P_{mid}, R_{F|i}) \ge 0,
(7)


DMesh: A Differentiable Representation for General Meshes
9
where Pmid is the middle point of the line segment LF |i = LF ∩Ci. The existence
of Pmid is guaranteed, because LF is on the boundary of Ci if F3 ∈WDT(P).
Note that we can compute Eq. 7 efficiently by projecting Pmid to the planes that
comprise RF |i, because of convexity. This alone reduces a lot of computational
burden, because we only have to gather planes that would possibly comprise
RF |i, instead of explicitly constructing it 6. Also, note that δ1 is a lower bound
of δ by definition at Eq. 3.
When F3 /
∈WDT(P), we use following δ2:
  \la b el  {e q :delt a _li n e_2} \delta _{2}(L_{F}, R_{F|i}) = \tau _{2}(L_{F}, C_{i}) \le 0.
(8)
Note that this is lower bound of δ when F3 does not exist, because Ci is a
subset of RF |i. Since we can readily obtain Ci from current Power diagram, we
can compute minimum distances between Li and line segments on the boundary
of Ci to evaluate Eq. 8.
To sum up, we redefine δ(LF , RF |i) as follows.
  \d e lt a ( L
_
{
F
}, R_ { F| i})
 =
 \l
eft \ {  \ beg in { ar ray } {rc
l}  \delta _{1}(L_F, R_{F|i}) & \mbox {if} & \exists F_3 \\ \delta _{2}(L_F, R_{F|i}) & \mbox {else if} & \exists C_{i} \wedge \nexists F_3 \\ -\infty & \mbox {else} \end {array}\right .
(9)
Even though this formulation gives a lower bound of Eq. 4, note that when the
original function evaluates to 0, this relaxation also evaluates to 0. Therefore, we
can still use sigmoid function of Eq. 6 to get differentiable existence probability.
Note that in these relaxations, we need to obtain every Power cell Ci, which
can be achieved by computing WDT for current point configuration. Please see
Appendix 7 and 9 for more details about our formulation, and how it is used in
the real optimization process.
3.4
Loss Functions
DMesh could be reconstructed from various types of inputs, such as meshes,
point clouds and multi-view images. Given those inputs, we optimize it by min-
imizing the specific energy functions leveraging the existence probabilities Λ(F)
of faces F. Here we briefly introduce how we define the reconstruction losses and
additional regularization losses that we use in the optimization process. Please
see Appendix 8 for more detailed explanations for these loss functions.
Reconstruction Loss (Lrecon) First, we assume that we are given a ground
truth mesh, which is comprised of points P and faces F, and we need to represent
it with our representation. In this case, we can easily see that we should maximize
Λ(F), as we already know that they exist in the mesh. In contrast, if we say ¯
F
as the remaining set of faces that can be defined on P, we notice that we should
6 In our experiments, during optimization process, we keep a set of planes that were
on Power cell Ci for each point, and update it during optimization.


10
S. Son et al.
minimize Λ(¯
F). Likewise, the reconstruction loss for mesh input can be defined
by this explicit connectivity information (Appendix 8.1).
However, when it comes to mesh reconstruction from point clouds or multi-
view images, we need to use another form of reconstruction loss. Commonly,
we exploit the probabilistic nature of our formulation in defining reconstruction
loss for these inputs. For instance, for point cloud, we formulate our loss mainly
based on Chamfer Distance (CD) loss, and compute the “expected” CD using
our face probabilities (Appendix 8.2). For multi-view images, we define our loss
based on rendering loss, which can be computed as L1 loss between the images
of our models rendered by a differentiable renderer and the given images. Here
we interpret the face probabilities as face opacities in the rendering process.
To allow gradients to flow across the face opacities, we implemented efficient
differentiable renderers. Please see Appendix 8.3 for details about them.
Fig. 5: Results with different λweight.
Regularizations
During optimiza-
tion, we can employ various regular-
izations to facilitate the process and
enhance the final mesh quality. The
first regularization that we introduce
is weight regularization (Lweight),
which works on the the dual Power Di-
agram of WDT (Appendix 8.4). Using
this regularization, we intend to reduce the structural complexity of WDT, and
discard unnecessary points that are not required to represent our mesh. Note
that we can use this regularization because we use WDT, not DT. Using this
regularization, we can control the final mesh complexity, as shown in Figure 5.
The next regularization is designed to guide real values of points, which is
called as real regularization (Lreal). This regularization aims at enforcing
nearby points to have similar real values. At the same time, it increases real
values of points that are adjacent to the points of high real values (Appendix 8.5).
This regularization facilitates the optimization process by removing holes or
inner structures of the mesh (Appendix 9), and making the faces near current
surface to be considered with higher probabilities than the others.
The final regularization aims at improving the quality of the triangle faces on
the mesh, which we name as quality regularization (Lqual). To be specific, we
minimize the average expected aspect ratio of the faces (Appendix 8.6). Using
this regularization, we intend to remove thin triangles on the mesh.
Total Loss To sum up, our final loss function can be written as follows:
  L = L_ { recon} +  \lambd a  _{we i ght} \ cdot L _{weight} + \lambda _{real} \cdot L_{real} + \lambda _{qual} \cdot L_{qual}, 
where λ values are hyperparameters. In Appendix 10, we provide values for
these hyperparameters for every experiment. Also, in Appendix 10.3, we present
ablation studies for these regularizations.


DMesh: A Differentiable Representation for General Meshes
11
4
Experiments and Applications
In this section, we provide experimental results that show the efficacy of our
approach. First, when we are given a ground truth mesh, we optimize the point
attributes to restore the mesh. With this experiment, we directly prove the differ-
entiability of our design and show the representation power of DMesh. Next, we
conduct experiments about 3D reconstruction from point clouds and multi-view
images to show how our differentiable formulation can be used in downstream
applications. We also show how the regularization affects the reconstruction re-
sults through ablation studies.
For the first mesh reconstruction problem, we used three models from Stan-
ford 3D scanning repository [13]. For point cloud and multi-view reconstruction
tasks, we used 4 closed-surface models from Thingi32 dataset [53], 4 open-surface
models from DeepFashion3D dataset [18], and 3 additional general models that
are comprised of both closed and open surfaces from Objaverse dataset [14] and
Adobe Stock, to accommodate meshes of various topology. Each of these kinds
of models is denoted as “closed”, “open”, and “mixed” model in this section.
We implemented our main algorithm for computing face existence proba-
bilites and differentiable renderer used for multi-view image reconstruction in
CUDA [37]. Since we need to compute WDT before running the CUDA algo-
rithm, we used WDT implementation of CGAL [19]. On top of that, we imple-
mented the rest of logic with Pytorch [41]. All of the experiments were run on a
system with AMD EPYC 7R32 CPU and Nvidia A10 GPU.
4.1
Mesh to DMesh
Table 1: Mesh reconstruction results.
-
Bunny Dragon Buddha
RE 99.78% 99.72% 99.64%
FP 0.00% 0.55%
0.84%
In this experiment, we demonstrate
that we can preserve most of the
faces in the original ordinary mesh
after converting it to DMesh using
the mesh reconstruction loss intro-
duced in Section 3.4. Please see Ap-
pendix 9.1 to learn about the details of the entire optimization process.
Fig. 6: Reconstruction re-
sult that has mesh pattern
adaptive to local geome-
try.
In Table 1, we show the recovery ratio (RE) and
false positive ratio (FP) of faces in our reconstructed
mesh. Note that we could recover over 99% of faces
in the original mesh, while only having under 1% of
false faces. Please see Appendix 10.1 for more details.
This result shows that our differentiable formulation
is correct, but also tells us that there is a limitation
in converting the original mesh into DMesh using con-
nectivity information. To overcome this limitation, we
can reconstruct mesh using other reconstruction losses
as discussed in next section. Interestingly, under some
occasions, we could observe that our optimized mesh
exhibits artificial quad-mesh like pattern (Figure 6),


12
S. Son et al.
Fig. 7: Point cloud reconstruction results. For a given point cloud sampled from
ground truth mesh in (a), our method (b) successfully restores the origi-
nal shape without losing much much detail. In contrast, PSR [20] (c) and
VoroMesh [31] (d) fail for open and mixed surface models. NDC [10] (e) exhibits arti-
facts from grids.
even if we optimize our mesh without ground truth connectivity information,
which shows potential ability of our method.
4.2
Point Cloud & Multi-View Reconstruction
Table 2: Statistics for Point Cloud (PC) and Multi-
View (MV) Reconstruction. Best results are high-
lighted in bold.
Methods
CD (10−3) ↓
Time
(sec) ↓
Closed Open Mixed
PC
Ours
7.42
6.87
8.06
775.05
PSR
7.15
26.94 67.18
10.61
VoroMesh 7.30
26.31 99087.64 12.18
NDC
7.30
6.83
8.25
3.48
MV
Ours
15.56 11.11 18.33
1434
Flexicube 31.23
34.91 25.15
56.47
NIE
31.54
67.37 43.05
6696.43
In this experiment, we aim
to reconstruct a mesh from
partial geometric data, such
as (oriented) point clouds or
multi-view images. For point
cloud reconstruction, we sam-
pled 100K points from the
ground
truth
mesh.
Even
though our formulation can
use normal information for
better
reconstruction
(Fig-
ure 9), we only use point posi-
tions for fair comparison. For
multi-view reconstruction, we rendered diffuse and depth images of the ground
truth mesh from 64 view points. In Appendix 10, we illustrated the example in-
puts for these experiments. Also, please see Appendix 9 to see the initialization
and densification strategy we took in these experiments.


DMesh: A Differentiable Representation for General Meshes
13
Fig. 8: Multi-view Reconstruction results. For given
images captured at multiple viewpoints around the
ground truth mesh in (a), our mesh (b) succeeds in recon-
structing overall shapes for every model, with small arti-
facts. However, since (c) Flexicube [44] and (d) NIE [32]
rely on volumetric principles, they produce wrong meshes
for open and mixed mesh models.
Fig. 9: Point cloud recon-
struction results from ori-
ented points. (Up) Recon-
struction with λnormal
=
0.001 (Down) Reconstruc-
tion with λnormal = 0.01.
To validate our approach, we compare our results with various approaches.
When it comes to point cloud reconstruction, we first compare our result with
classical Screened Poisson Surface Reconstruction (PSR) method [20] 7. Then, to
compare our method with optimization based approach, we use recent VoroMesh [31]
method, which shares similar principles with us. Note that these two methods are
essentially volumetric approach, and thus are not tailored for open surfaces. To
compare our method also for the open surfaces, we use Neural Dual Contouring
(NDC) [10], even though it is learning-based approach. Finally, for multi-view
reconstruction task, we compare our results with Flexicube [44] and Neural Im-
plicit Evolution (NIE) [32], which correspond to volumetric approaches that can
directly produce mesh of varying geometric topology for given visual inputs.
In Figure 7 and 8, we visualize the reconstruction results along with the
ground truth mesh. In general, volumetric approaches like PSR, VoroMesh, and
Flexicube, capture fine details better than our methods for closed models. This is
mainly because we currently have limitation in the mesh resolution that we can
produce with our method. NIE, which is also based on volumetric principles,
generates overly smoothed reconstruction results. However, when it comes to
open or mixed mesh models, we can observe that these methods fail, usually
with false internal structures or self-intersecting faces (Appendix 10.2). Since
NDC leverages unsigned information, it can handle these cases without much
7 We also feed in point orientations for PSR, which is optional for our method.


14
S. Son et al.
problem as ours. However, we can observe step-like visual artifacts coming from
its usage of grid in the final output, which requires post-processing.
Table 2 presents quantitative comparisons with other methods. Chamfer Dis-
tance (CD) based on L1-norm is computed between the reconstructed mesh and
the ground truth mesh, along with an average for different types of meshes.
Additionally, we report the average running time of each method. In the table,
we observe that CD error generally aligns with the visual renderings. Compared
to the other methods, our method exhibits generally better, or comparable re-
sults across every model for both point cloud and multi-view reconstruction.
However, notice that our method has clear limitation in computation time in
the current implementation. This is partially because we run too many steps
(Appendix 10.2) for the sake of completeness of every model, but many models
converge very fast in practice, as shown in Figure 1 when we use sample points
for initialization.
5
Conclusion and Future Directions
Our method achieves a more effective and complete representation of meshes of
various topology than existing methods, but opens up areas for future research.
– Computational cost: Currently, the resolution of DMesh is largely constrained
by computational cost. Even though we succeeded in decreasing computa-
tional burden through our theoretical relaxation and CUDA implementation,
it costs more than a second to process over 100K vertices, mainly because
we run WDT for the entire points at every step (Appendix 9.2).
– Non-manifoldness: As we have claimed so far, DMesh shows much better
generalization than the other methods as it does not have any constraints
on the mesh connectivity. However, due to this relaxation of constraint, small
holes or “ears” in the reconstruction can appear as “non-manifoldness”. They
become more evident when there is no strong supervision or appropriate
regularization. Multi-view image reconstruction with occlusions is a typi-
cal example. It is possible to eliminate them up to some extent by using
additional measures (Appendix 9.2). But, more structured mechanism to
eliminate them completely and generate geometric entities that align with
more formal definition of “mesh” [4] would be a natural extension.
To address the aformentioned limitations, it is possible to accelerate the
main algorithm by carefully constraining the points to update or imposing some
bounds on the step size to minimize costly WDT at every iteration. Also, we
can investigate if GPU acceleration is possible for WDT [6]. Next, additional
geometric constraints can be imposed to remove non-manifold edges. Adopting
regularizations like Eikonal loss could be one possible approach, as we can encode
unsigned distance information in the points.
Further research can also extend this work to solve other challenging problems
(e.g. 3D reconstruction from real world images) or other related applications (e.g.
3D mesh generative model) in the future.


DMesh: A Differentiable Representation for General Meshes
15
Acknowledgements We thank Zhiqin Chen and Matthew Fisher for helpful
advice. This research is a joint collaboration between Adobe and University of
Maryland at College Park. This work has been supported in part by Adobe,
IARPA, UMD-ARL Cooperate Agreement, and Dr. Barry Mersky and Capital
One Endowed E-Nnovate Professorships.
References
1. Amenta, N., Bern, M., Eppstein, D.: The crust and the β-skeleton: Combinato-
rial curve reconstruction. Graphical models and image processing 60(2), 125–135
(1998)
2. Amenta, N., Bern, M., Kamvysselis, M.: A new voronoi-based surface reconstruc-
tion algorithm. In: Proceedings of the 25th annual conference on Computer graph-
ics and interactive techniques. pp. 415–421 (1998)
3. Aurenhammer, F., Klein, R., Lee, D.T.: Voronoi diagrams and Delaunay triangu-
lations. World Scientific Publishing Company (2013)
4. Botsch, M., Kobbelt, L., Pauly, M., Alliez, P., Lévy, B.: Polygon mesh processing.
CRC press (2010)
5. Brandt, J.W., Algazi, V.R.: Continuous skeleton computation by voronoi diagram.
CVGIP: Image understanding 55(3), 329–338 (1992)
6. Cao, T.T., Nanjappa, A., Gao, M., Tan, T.S.: A gpu accelerated algorithm for
3d delaunay triangulation. In: Proceedings of the 18th meeting of the ACM SIG-
GRAPH Symposium on Interactive 3D Graphics and Games. pp. 47–54 (2014)
7. Chen, A., Xu, Z., Geiger, A., Yu, J., Su, H.: Tensorf: Tensorial radiance fields. In:
European Conference on Computer Vision (ECCV) (2022)
8. Chen, A., Xu, Z., Wei, X., Tang, S., Su, H., Geiger, A.: Dictionary fields: Learning
a neural basis decomposition. ACM Trans. Graph. (2023)
9. Chen, W., Ling, H., Gao, J., Smith, E., Lehtinen, J., Jacobson, A., Fidler, S.:
Learning to predict 3d objects with an interpolation-based differentiable renderer.
Advances in neural information processing systems 32 (2019)
10. Chen, Z., Tagliasacchi, A., Funkhouser, T., Zhang, H.: Neural dual contouring.
ACM Transactions on Graphics (TOG) 41(4), 1–13 (2022)
11. Chen, Z., Tagliasacchi, A., Zhang, H.: Bsp-net: Generating compact meshes via
binary space partitioning. In: Proceedings of the IEEE/CVF Conference on Com-
puter Vision and Pattern Recognition. pp. 45–54 (2020)
12. Cignoni, P., Callieri, M., Corsini, M., Dellepiane, M., Ganovelli, F., Ranzuglia,
G., et al.: Meshlab: an open-source mesh processing tool. In: Eurographics Italian
chapter conference. vol. 2008, pp. 129–136. Salerno, Italy (2008)
13. Curless, B., Levoy, M.: A volumetric method for building complex models from
range images. In: Proceedings of the 23rd annual conference on Computer graphics
and interactive techniques. pp. 303–312 (1996)
14. Deitke, M., Schwenk, D., Salvador, J., Weihs, L., Michel, O., VanderBilt, E.,
Schmidt, L., Ehsani, K., Kembhavi, A., Farhadi, A.: Objaverse: A universe of
annotated 3d objects. In: Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition. pp. 13142–13153 (2023)
15. Diazzi, L., Panozzo, D., Vaxman, A., Attene, M.: Constrained delaunay tetra-
hedrization: A robust and practical approach. ACM Transactions on Graphics
(TOG) 42(6), 1–15 (2023)


16
S. Son et al.
16. Guillard, B., Remelli, E., Lukoianov, A., Richter, S.R., Bagautdinov, T., Baque,
P., Fua, P.: Deepmesh: Differentiable iso-surface extraction. arXiv preprint
arXiv:2106.11795 (2021)
17. Hanocka, R., Hertz, A., Fish, N., Giryes, R., Fleishman, S., Cohen-Or, D.: Meshcnn:
a network with an edge. ACM Transactions on Graphics (ToG) 38(4), 1–12 (2019)
18. Heming, Z., Yu, C., Hang, J., Weikai, C., Dong, D., Zhangye, W., Shuguang, C.,
Xiaoguang, H.: Deep fashion3d: A dataset and benchmark for 3d garment recon-
struction from single images. In: Computer Vision – ECCV 2020. pp. 512–530.
Springer International Publishing (2020)
19. Jamin, C., Pion, S., Teillaud, M.: 3D triangulations. In: CGAL User and Reference
Manual. CGAL Editorial Board, 5.6 edn. (2023), https://doc.cgal.org/5.6/
Manual/packages.html#PkgTriangulation3
20. Kazhdan, M., Hoppe, H.: Screened poisson surface reconstruction. ACM Transac-
tions on Graphics (ToG) 32(3), 1–13 (2013)
21. Kerbl, B., Kopanas, G., Leimkühler, T., Drettakis, G.: 3d gaussian splatting for
real-time radiance field rendering. ACM Transactions on Graphics 42(4) (2023)
22. Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980 (2014)
23. Laine, S., Hellsten, J., Karras, T., Seol, Y., Lehtinen, J., Aila, T.: Modular primi-
tives for high-performance differentiable rendering. ACM Transactions on Graphics
(TOG) 39(6), 1–14 (2020)
24. Lee, J.: Introduction to topological manifolds, vol. 202. Springer Science & Business
Media (2010)
25. Liao, Y., Donne, S., Geiger, A.: Deep marching cubes: Learning explicit surface
representations. In: Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition. pp. 2916–2925 (2018)
26. Liu, L., Gu, J., Lin, K.Z., Chua, T.S., Theobalt, C.: Neural sparse voxel fields.
NeurIPS (2020)
27. Liu, S., Li, T., Chen, W., Li, H.: Soft rasterizer: A differentiable renderer for image-
based 3d reasoning. In: Proceedings of the IEEE/CVF International Conference
on Computer Vision. pp. 7708–7717 (2019)
28. Liu, Y.T., Wang, L., Yang, J., Chen, W., Meng, X., Yang, B., Gao, L.: Neudf:
Leaning neural unsigned distance fields with volume rendering. In: Proceedings
of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp.
237–247 (2023)
29. Long, X., Lin, C., Liu, L., Liu, Y., Wang, P., Theobalt, C., Komura, T., Wang,
W.: Neuraludf: Learning unsigned distance fields for multi-view reconstruction of
surfaces with arbitrary topologies. In: Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition. pp. 20834–20843 (2023)
30. Lorensen, W.E., Cline, H.E.: Marching cubes: A high resolution 3d surface con-
struction algorithm. In: Seminal graphics: pioneering efforts that shaped the field,
pp. 347–353 (1998)
31. Maruani, N., Klokov, R., Ovsjanikov, M., Alliez, P., Desbrun, M.: Voromesh:
Learning watertight surface meshes with voronoi diagrams. In: Proceedings of the
IEEE/CVF International Conference on Computer Vision. pp. 14565–14574 (2023)
32. Mehta, I., Chandraker, M., Ramamoorthi, R.: A level set theory for neural implicit
evolution under explicit flows. In: European Conference on Computer Vision. pp.
711–729. Springer (2022)
33. Melkemi, M.: A-shapes of a finite point set. In: Proceedings of the thirteenth annual
symposium on Computational geometry. pp. 367–369 (1997)


DMesh: A Differentiable Representation for General Meshes
17
34. Melkemi, M., Djebali, M.: Weighted a-shape: a descriptor of the shape of a point
set. Pattern Recognition 34(6), 1159–1170 (2001)
35. Mildenhall, B., Srinivasan, P.P., Tancik, M., Barron, J.T., Ramamoorthi, R., Ng,
R.: Nerf: Representing scenes as neural radiance fields for view synthesis. Commu-
nications of the ACM 65(1), 99–106 (2021)
36. Munkberg, J., Hasselgren, J., Shen, T., Gao, J., Chen, W., Evans, A., Müller, T.,
Fidler, S.: Extracting triangular 3d models, materials, and lighting from images.
In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition. pp. 8280–8290 (2022)
37. Nickolls, J., Buck, I., Garland, M., Skadron, K.: Scalable parallel programming
with cuda: Is cuda the parallel programming model that application developers
have been waiting for? Queue 6(2), 40–53 (2008)
38. Nicolet, B., Jacobson, A., Jakob, W.: Large steps in inverse rendering of geometry.
ACM Transactions on Graphics (TOG) 40(6), 1–13 (2021)
39. Oechsle, M., Peng, S., Geiger, A.: Unisurf: Unifying neural implicit surfaces and
radiance fields for multi-view reconstruction. In: International Conference on Com-
puter Vision (ICCV) (2021)
40. Palfinger, W.: Continuous remeshing for inverse rendering. Computer Animation
and Virtual Worlds 33(5), e2101 (2022)
41. Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z.,
Desmaison, A., Antiga, L., Lerer, A.: Automatic differentiation in pytorch (2017)
42. Rakotosaona, M.J., Aigerman, N., Mitra, N.J., Ovsjanikov, M., Guerrero, P.: Dif-
ferentiable surface triangulation. ACM Transactions on Graphics (TOG) 40(6),
1–13 (2021)
43. Shen, T., Gao, J., Yin, K., Liu, M.Y., Fidler, S.: Deep marching tetrahedra: a
hybrid representation for high-resolution 3d shape synthesis. Advances in Neural
Information Processing Systems 34, 6087–6101 (2021)
44. Shen, T., Munkberg, J., Hasselgren, J., Yin, K., Wang, Z., Chen, W., Gojcic, Z.,
Fidler, S., Sharp, N., Gao, J.: Flexible isosurface extraction for gradient-based
mesh optimization. ACM Transactions on Graphics (TOG) 42(4), 1–16 (2023)
45. Shewchuk, J.R.: Constrained delaunay tetrahedralizations and provably good
boundary recovery. IMR 193, 204 (2002)
46. Si, H.: Constrained delaunay tetrahedral mesh generation and refinement. Finite
elements in Analysis and Design 46(1-2), 33–46 (2010)
47. Wang, P., Liu, L., Liu, Y., Theobalt, C., Komura, T., Wang, W.: Neus: Learning
neural implicit surfaces by volume rendering for multi-view reconstruction. arXiv
preprint arXiv:2106.10689 (2021)
48. Wang, Y., Han, Q., Habermann, M., Daniilidis, K., Theobalt, C., Liu, L.: Neus2:
Fast learning of neural implicit surfaces for multi-view reconstruction. In: Pro-
ceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)
(2023)
49. Wei, X., Xiang, F., Bi, S., Chen, A., Sunkavalli, K., Xu, Z., Su, H.: Neumanifold:
Neural watertight manifold reconstruction with efficient and high-quality rendering
support. arXiv preprint arXiv:2305.17134 (2023)
50. Yariv, L., Gu, J., Kasten, Y., Lipman, Y.: Volume rendering of neural implicit
surfaces. In: Thirty-Fifth Conference on Neural Information Processing Systems
(2021)
51. Yariv, L., Kasten, Y., Moran, D., Galun, M., Atzmon, M., Ronen, B., Lipman, Y.:
Multiview neural surface reconstruction by disentangling geometry and appear-
ance. Advances in Neural Information Processing Systems 33 (2020)


18
S. Son et al.
52. Zhang, K., Riegler, G., Snavely, N., Koltun, V.: Nerf++: Analyzing and improving
neural radiance fields. arXiv:2010.07492 (2020)
53. Zhou, Q., Jacobson, A.: Thingi10k: A dataset of 10,000 3d-printing models. arXiv
preprint arXiv:1605.04797 (2016)
54. Zhou, Y., Wu, C., Li, Z., Cao, C., Ye, Y., Saragih, J., Li, H., Sheikh, Y.: Fully
convolutional mesh autoencoder using efficient spatially varying kernels. Advances
in neural information processing systems 33, 9251–9262 (2020)


DMesh: A Differentiable Representation for General Meshes
19
Table 3: Traits of different optimization-based shape reconstruction methods.
Methods
Closed Open Diff. Mesh Diff. Render. Geo. Topo. Mesh Topo. Manifold
Template Mesh [38,40]
O
O
O
O
X
X
O
Neural SDF [47,48]
O
X
X
O
O
X
O
Neural UDF [28,29]
O
O
X
O
O
X
△
Diff. Isosurface [36,43,44]
O
X
O
O
O
X
O
DMesh (Ours)
O
O
O
O
O
O
X
6
Comparison to Other Shape Reconstruction Methods
Here we provide conceptual comparisons between our approach and the other
optimization-based 3D reconstruction algorithms, which use different shape rep-
resentations. To be specific, we compared our method with mesh optimiza-
tion methods starting from template mesh [38, 40], methods based on neural
signed distance fields (SDF) [47,48], methods based on neural unsigned distance
fields (UDF) [28, 29], and methods based on differentiable isosurface extrac-
tion [36,43,44]. We used following criteria to compare these methods.
– Closed surface: Whether or not the given method can reconstruct, or repre-
sent closed surfaces.
– Open surface: Whether or not the given method can reconstruct, or represent
open surfaces.
– Differentiable Meshing: Whether or not the given method can produce gra-
dients from the loss computed on the final mesh.
– Differentiable Rendering: Whether or not the given method can produce
gradients from the loss computed on the rendering results.
– Geometric topology: Whether or not the given method can change geomet-
ric topology of the shape. Here, geometric topology defines the continuous
deformation of Euclidean subspaces [24]. For instance, genus of the shape is
one of the traits that describe geometric topology.
– Mesh topology: Whether or note the given method can produce gradients
from the loss computed on the mesh topology, which denotes the structural
configuration, or edge connectivity of a mesh.
– Manifoldness: Whether or not the given method guarantees manifold mesh.
In Table 3, we present a comparative analysis of different methods. Note that
our method meets all criteria, only except manifoldness. It is partially because
our method does not assume volume, which is the same for methods based on
neural UDF. However, because our method does not leverage smoothness prior
of neural network like those methods, it could exhibit high frequency noises in
the final mesh. Because of this reason, we gave △to the neural UDF methods,
while giving X to our approach.
Likewise, DMesh shows promise in addressing the shortcomings found in pre-
vious research. Nonetheless, it has its own set of limitations (Section 5). Identi-
fying and addressing these limitations is crucial for unlocking the full potential
of our method.


20
S. Son et al.
7
Details about Section 3.2
7.1
Mathematical Definitions
Here, we provide formal mathematical definitions of the terms used in Sec-
tion 3.2. Please refer to [3] for further discussion on this particular topic.
Half Plane Given a set of points P ∈Rd and their weights W ∈R, we denote
an i-th weighted point as (pi, wi). Then, we can define a hyperplane H(i, j),
which we call as a half plane, that divides the domain into two half spaces Hi<j
and Hj<i that satisfy the following relationship:
  H_ { i< j } =  \{  x \in \mathbb {R}^{d} \, | \, {||x - p_{i}||}^{2} - w_i \le {||x - p_{j}||}^{2} - w_j \}. p
Note that this half plane becomes an infinite line when d = 2, and an infinite
plane when d = 3.
Power Cell Based on this definition, the Power cell Ci of a point pi can be
described as an intersection of half spaces between pi and the other points pj.
  C _{ i } =  \ { x \ in  \ mathbb {R}^{d} \, | \, x \in H_{i<j}, \forall j \neq i \}.
Note that there could be no Power cell Ci for a certain point pi if its weight wi
is relatively smaller than those of its neighboring points.
Reduced Power Cell As mentioned in Section 3.2, we adopt the concept of
“reduced” Power cell from [42]. Unlike the ordinary Power cell, reduced Power
cell depends on the face F. That is, if we define F = {p1, p2, ..., pd}, the reduced
Power cell RF |i for a point pi ∈F is defined as
  R_ { F| i } =  \ { x \ in  
\ mathbb {R}^{d} \, | \, x \in H_{i<j}, \forall j \notin F \}.
Therefore, RF |i can vary depending on F. We consider only the points not
included in F to define this reduced Power cell, as opposed to considering all
points other than pi. Consequently, the following relationship holds:
  C _{ i} \subseteq R_{F|i}, \forall F.
Dual Line Now, for a given (d −1)-simplex face F = {p1, p2, ..., pd}, we can
construct its dual line LF as an intersection of the half spaces that are defined
by the points of F.
  L
_
{F} &= 
\big cap _{(i, j) \in F} H(i, j).
Note that LF becomes an infinite line in both d = 2 and d = 3 cases. As
discussed in Section 3.2, when the face F exists in WDT, a subset of LF exists as
an edge in Power diagram. This relationship forms the bases of our differentiable
formulation.


DMesh: A Differentiable Representation for General Meshes
21
Differentiable Min Operation In Section 3.2, we used a differentiable min
operator dmin to define Λreal. Formally, we define dmin as follows.
  dmin(x _{1 }, x _2,  . .
.
, x_k, \a lpha ) =  \ f ra
c
 {\sum _{ i=1, .. . , 
k}\exp (-x_{i} \cdot \alpha ) \cdot x_{i}}{\sum _{i=1, ..., k}\exp (-x_{i} \cdot \alpha )}.
Note that it becomes more non-differentiable as α becomes larger.
7.2
Differentiable Power Cell Existence
Even though our formulation in Section 3.2 is differentiable, we wish to highlight
a potential issue here.
According to our formulation, there is a scenario in which a point might lose
its Power cell because its updated weight becomes relatively smaller compared
to those of its neighbors. In such a case, the existence probability of a face
containing that point may abruptly decrease from a value greater than 0.5 to 0,
which is not desirable.
To address this problem, we can introduce an additional constraint regarding
the existence of Power cells. Specifically, a Power cell Ci exists if and only if there
is a face F that includes the point pi. Consequently, the following relationship
is established:
  \ e xi s ts C_{i }  \Le f tr igh t arrow \exists F \in \mathbb {I}_{wdt}(F) \Leftrightarrow \delta (L_{F}, R_{F|i}) > 0. 
Based on this observation, we can define a differentiable Power cell existence
probability function, which is parameterized by a threshold ϵpc and sigmoid
parameter αpc,
  \Lamb d a _{p c }
(
C _ i
)
 = \ s ig ma ( \alpha _{pc} \cdot (\sum _{F \in \bar {F} } \delta (L_{F}, R_{F|i}) - \epsilon _{pc})), 
where ¯
F is a set of faces that has point pi. Using this function, we can newly
define Λwdt in Eq. 6 for a triangular face F3 as
  
\Lambda  _{wdt}^{ \ ast }(F_{3})  = \Lamb da _{wdt}(F_{3}) \cdot \min (\Lambda _{pc}(C_i), \Lambda _{pc}(C_j), \Lambda _{pc}(C_k)). 
(10)
Here, we used the min operation because F3 ceases to exist when any of its
points loses its Power cell. With this operation, the probability function becomes
fully differentiable, even when points gain or lose their Power cells during the
optimization process.
However, when we implemented this new formulation and compared it with
the existing one, we observed no significant difference between the two. We
hypothesize that this is because, in most cases, faces that need to exist are
updated to increase Eq. 6, which, in turn, reinforces the existence of Power
cells for the points constituting the face. Therefore, although we omitted this
formulation in the final version, we introduce it here to ensure the completeness
of our discussion.


22
S. Son et al.
8
Loss Functions
Here we provide formal definitions for the loss functions that we use in the paper.
8.1
Mesh to DMesh
In this section, we explore the loss function used to transform the ground truth
mesh into our DMesh representation. As previously mentioned in Section 3.4,
the explicit definition of ground truth connectivity in the provided mesh allows
us to establish a loss function based on it.
Building on the explanation in Section 3.4, if the ground truth mesh consists
of vertices P and faces F, we can construct an additional set of faces ¯
F. These
faces are formed from vertices in P but do not intersect with faces in F.
 
 \ ba r  { \math bb  {F}} = \mathb b {F }^{\ast } -  \ mathbb {F}, \text { where } \mathbb {F}^{\ast } = \text { every possible face combination on } \mathbb {P}.
Then, we notice that we should maximize the existence probabilities of faces
in F, but minimize those of faces in ¯
F. Therefore, we can define our reconstruction
loss function as
  \lab e l
 
{ eq
:rec o
n
- ex
p
-1} L_{recon} = -\sum _{F \in \mathbb {F}}\Lambda (F) + \sum _{F \in \bar {\mathbb {F}}}\Lambda (F). 
(11)
If the first term of the loss function mentioned above is not fully optimized, it
could lead to the omission of ground truth faces, resulting in a poorer recovery
ratio (Section 4.1). Conversely, if the second term is not fully optimized, the
resulting DMesh might include faces absent in the ground truth mesh, leading
to a higher false positive ratio (Section 4.1). Refer to Appendix 9.1 for details on
how this reconstruction loss is integrated into the overall optimization process.
8.2
Point Cloud Reconstruction
In the task of point cloud reconstruction, we reconstruct the mesh by minimiz-
ing the (L1-norm based) expected Chamfer Distance (CD) between the given
point cloud (Pgt) and the sample points (Pours) from our reconstructed mesh.
We denote the CD from Pgt to Pours as CDgt, and the CD from Pours to Pgt
as CDours. The final reconstruction loss is obtained by combining these two
distances.
  \lab e l {e q :pc-recon-loss} L_{recon} = CD_{gt} + CD_{ours}. 
(12)
Sampling Pours To compute these terms, we start by sampling Pours from our
current mesh. First, we sample a set of faces that we will sample points from.
We consider the areas of the triangular faces and their existence probabilities.
To be specific, we define η(F) for a face F as
 
 \ba r  {\et
a }( F ) = \ L a
mbda (F), \quad \eta (F) = F_{area} \cdot \bar {\eta }(F),


DMesh: A Differentiable Representation for General Meshes
23
and define a probability to sample F from the entires faces F as
  P_{sampl e
}(F)
 
=  \f rac  {\eta (F)}{\sum _{F'\in \mathbb {F}} \eta (F') }.
We sample N faces from F with replacement and then uniformly sample a
single point from each selected face to define Pours. In our experiments, we set
N to 100K.
In this formulation, we sample more points from faces with a larger area
and higher existence probability to improve sampling efficiency. However, we
observed that despite these measures, the sampling efficiency remains low, lead-
ing to slow convergence. This issue arises because, during optimization, there is
an excessive number of faces with very low existence probability.
To overcome this limitation, we decided to do stratified sampling based on
point-wise real values and cull out faces with very low existence probabilities.
To be specific, we define two different η functions:
 
 \bar  {\eta _ { 1}}(F) &= \Lam
bda _ { wdt}( F )
 \cdo
t
 \min  (\psi _ { i}, \ps i _ {j},
 \psi  _{k}) ,  
\quad \eta _{1}(F) = F_{area} \cdot \bar {\eta _{1}}(F) \\ \bar {\eta _{2}}(F) &= \Lambda _{wdt}(F) \cdot \max (\psi _{i}, \psi _{j}, \psi _{k}), \quad \eta _{2}(F) = F_{area} \cdot \bar {\eta _{2}}(F)
where (ψi, ψj, ψk) are the real values of the points that comprise F. Note
that η1 is the same as η 8.
For the faces in F, we first calculate the ¯
η1 and ¯
η2 values and eliminate faces
with values lower than a predefined threshold ϵη. We denote the set of remaining
faces as F1 and F2. Subsequently, we sample N
2 faces from F1 and the other N
2
faces from F2, using the following two sampling probabilities:
  P_{sample,  
1}(F)
 
=  \fr ac { \et
a _{1}(F)}{\ s
um _{
F
' \in \mat hbb {F}_{1}} \eta _{1}(F') }, \quad P_{sample, 2}(F) = \frac {\eta _{2}(F)}{\sum _{F'\in \mathbb {F}_{2}} \eta _{2}(F') }.
The rationale behind this sampling strategy is to prioritize (non-existing)
faces closer to the current mesh over those further away. In the original η =
η1 function, we focus solely on the minimum real value, leading to a higher
sampling rate for existing faces. However, to remove holes in the current mesh,
it’s beneficial to sample more points from potential faces—those not yet existing
but connected to existing ones. This approach, using η2, enhances reconstruction
results by removing holes more effectively. Yet, there’s substantial potential to
refine this importance sampling technique, as we haven’t conducted a theoretical
analysis in this study.
Moreover, when sampling a point from a face, we record the face’s existence
probability alongside the point. Additionally, if necessary, we obtain and store
the face’s normal. For a point p ∈Pours, we introduce functions Λpt(·) and
Normal(·) to retrieve the face existence probability and normal, respectively:
8 We do not use differentiable min operator, as we do not require differentiability in
the sampling process.


24
S. Son et al.
  \Lam b da _{pt}
(\mathbf { p}) &= \Lam
bda ( F(\ math bf {p } )),  \quad Normal(\mathbf {p}) = F(\mathbf {p})_{normal}, \\ F(\mathbf {p}) &= \text {the face where $\mathbf {p}$ was sampled from}.
CDgt Now we introduce how we compute the CDgt, which is CD from Pgt to
Pours. For each point p ∈Pgt, we first find k-nearest neighbors of p in Pours,
which we denote as (p1, p2, ..., pk). Then, we define a distance function between
the point p and the k-nearest neighbors as follows, to accommodate the orien-
tation information:
 
 \be gin  {sp l it} \ l abel {e q :
cd-pd ist}
 \bar  
{D}(\ mat h b f  { p}, p_i)  &= ||\mat h bf {p} - p_i||_{2} + \lambda _{normal}\cdot \bar {D}_{n}(\mathbf {p}, p_i), \\ \text {where }\bar {D}_{n}(\mathbf {p}, p_i) &= 1 - |<\mathbf {p}_{normal}, Normal(p_i)>|, \end {split}
(13)
where λnormal is a parameter than determines the importance of point ori-
entation in reconstruction. If λnormal = 0, we only consider the positional infor-
mation of the sampled points.
After we evaluate the above distance function values for the k-nearest points,
we reorder them in ascending order. Then, we compute the following expected
minimum distance from p to Pours,
  D( \mathb f
 
{p}, \mat
h
bb { P}_ { ours} )  
&= \su
m _{i = 1,..p,k }  \bar {D}(\m
a
thbf { p}, p_{i}) \cd o t P(p_i) \cdot \bar {P}(p_i), \\ P(p_i) &= \Lambda _{pt}(p_i) \cdot \mathbb {I}_{prev}(F(p_{i}), \\ \bar {P}(p_i) &= \Pi _{i=1, ..., k-1} (1 - P(p_i)),
where Iprev is an indicator function that returns 1 only when the given face
has not appeared before in computing the above expected distance. For instance,
if the face ids for the reordered points were (1, 2, 3, 2, 3, 4), the Iprev function eval-
uates to (1, 1, 1, 0, 0, 1). This indicator function is needed, because if we select pi
as the nearest point to p with the probability Λpt(p), it means that we interpret
that the face corresponding to pi already exists, and then we would select pi on
the face as the nearest point to p rather than the other points that were sampled
from the same face, but have larger distance than pi and thus come after pi in
the ordered points.
Note that we dynamically change k during runtime to get a reliable esti-
mation of D(p, Pours). That is, for current k, if most of ¯
P(pk)s for the points
in Pgt are still large, it means that there is a chance that the estimation could
change a lot if we find and consider more neighboring points. Therefore, in our
experiments, if any point in Pgt has ¯
P(pk) larger than 10−4, we increase k by 1
for the next iteration. However, if there is no such point, we decrease k by 1 to
accelerate the optimization process.
Finally, we can compute CDgt by summing up the point-wise expected min-
imum distances.
  CD _
{
gt} =
 \su m _{\mathbf {p} \in \mathbb {P}_{gt}} D(\mathbf {p}, \mathbb {P}_{ours}).


DMesh: A Differentiable Representation for General Meshes
25
CDours In computing CDours, which is CD from Pours to Pgt, we also find
k-nearest neighbors for each point p ∈Pours, which we denote as (p1, p2, ..., pk).
Then, for a point p, we use the same distance function ¯
D in Eq. 13 to find the
distance between p and (p1, p2, ..., pk). After that, we select the minimum one
for each point, multiply the existence probability of each point, and then sum
them up to compute CDours.
  D( \mat h
bf 
{p}, \mat
h
bb {P}_{gt}) &= \min _{i=1,...,k} \bar {D}(\mathbf {p}, p_i), \\ CD_{ours} &= \sum _{\mathbf {p} \in \mathbb {P}_{ours}} \Lambda _{pt}(\mathbf {p}) \cdot D(\mathbf {p}, \mathbb {P}_{gt}). p
Finally, we can compute the final reconstruction loss for point clouds as
shown in Eq. 12.
8.3
Multi-View Reconstruction
When we are given multi-view images, we reconstruct the mesh by minimizing
the L1 difference between our rendered images and the given images. In this
work, we mainly use both diffuse and depth renderings to reconstruct the mesh.
If we denote the (Nimg) ground truth images of Npixel number of pixels
as Igt
i (i = 1, ..., Nimg), and our rendered images as Iours
i
, we can write the
reconstruction loss function as
  L_{r e
c
on} =  \frac
 
{1}{N_{img} 
\cdot
 N _{pix
e
l}}\sum _{i=1,...,N_{img}}|| \mathcal {I}^{gt}_{i} - \mathcal {I}^{ours}_{i} ||.
Then, we can define our rendered image as follows:
  I^{
o
u rs}_ {i } = \ math cal {F}(\mathbb {P, F}, \Lambda (\mathbb {F}), \mathbf {MV_{i}}, \mathbf {P_{i}}).
where F is a differentiable renderer that renders the scene for the given points
P, faces F, face existence probabilities Λ(F), i-th modelview matrix MVi ∈R4×4,
and i-th projection matrix Pi ∈R4×4. The differentiable renderer F has to
backpropagate gradients along P, F, and Λ(F) to update our point attributes.
Specifically, here we interpret Λ(F) as opacity for faces to use in the rendering
process. This is because opacity means the probability that a ray stops when
it hits the face, which aligns with our face existence probability well. For this
reason, we ignore faces with very low existence probability under some threshold
to accelerate the reconstruction, as they are almost transparent and do not
contribute to the rendering a lot.
To implement F, we looked through previous works dedicated for differ-
entiable rendering [23, 27]. However, we discovered that these methods incur
substantial computational costs when rendering a large number of (potentially)
semi-transparent triangles, as is the case in our scenario. Consequently, we de-
veloped two efficient, partially differentiable renderers that meet our specific
requirements. These renderers fulfill distinct roles within our pipeline—as de-
tailed in Appendix 9, our optimization process encompasses two phases within
a single epoch. The first renderer is employed during the initial phase, while the
second renderer is utilized in the subsequent phase.


26
S. Son et al.
(a) Rendered Images from FA
(b) Rendered Images from FA′
Fig. 10: Rendered images from two differentiable renderers, FA and FA′. Left and
right image corresponds to diffuse and depth rendering, respectively. (a) FA is our
(partially) differentiable renderer based on tile-based approach. (b) Since FA does not
produce visibility-related gradients, we additionally use FA′ [23] to render images and
integrate with ours.
FA If there are multiple semi-transparent faces in the scene, we have to sort the
faces that covers a target pixel with their (view-space) depth values, and iterate
through them until the accumulated transmittance is saturated to determine the
color for the pixel. Conducting this process for each individual pixel is not only
costly, but also requires a lot of memory to store information for backward pass.
Recently, 3D Gaussian Splatting [21] overcame this issue with tile-based ras-
terizer. We adopted this approach, and modified their implementation to render
triangular faces, instead of gaussian splats. To briefly introduce its pipeline, it
first assigns face-wise depth value by computing the view-space depth of its cen-
ter point. Then, after subdividing the entire screen into 16 × 16 tiles, we assign
faces to each tiles if they overlap. After that, by using the combination of tile
ID and the face-wise depth as a key, we get the face list sorted by depth value in
each tile. Finally, for each tile, we iterate through the sorted faces and determine
color and depth for each pixel as follows.
  
C
 = \sum _
{i = 1, . ..,
k} T _{i} \cdot \ \ a lpha _{i} \cdot C_i, \quad (T_i = \Pi _{j=1,...,i-1} (1 - \alpha _j)),
where Ti is the accumulated transmittance, αi is the opacity of the i-th face,
and Ci is the color (or depth) of the i-th face. Note that αi = Λ(Fi), as mentioned
above.
Even though this renderer admits an efficient rendering of large number of
semi-transparent faces, there are still two large limitations in the current imple-
mentation. First, the current implementation does not produce visibility-related
gradients (near face edges) to update point attributes. Therefore, we argue that
this renderer is partially differentiable, rather than fully differentiable. Next,
since it does not compute precise view-point depth for each pixel, its rendering
result can be misleading for some cases, as pointed out in [21].
To amend the first issue, we opt to use another differentiable renderer of [23],
which produces the visibility-related gradients that we lack. Since this renderer
cannot render (large number of) transparent faces as ours does, we only render


DMesh: A Differentiable Representation for General Meshes
27
(a) Extracted Mesh after phase 1
(b) Extracted Mesh after phase 2
Fig. 12: Reconstructed mesh from multi-view images, rendered in MeshLab’s [12] x-
ray mode to see inner structure. In multi-view reconstruction, we divide each epoch in
two phases. (a) After the first phase ends, where we do inaccurate depth testing, lots of
false inner faces are created. (b) To remove these inner faces, we require a renderer that
does the exact depth testing, which we use in the second phase. Also see Appendix 9.2
for details about post-processing step to remove the inner structure.
the faces with opacity larger than 0.5. Also, we set the faces to be fully opaque. If
we call this renderer as FA′, our final rendered image can be written as follows.
  \ma
t
h c
al {I}^ {o urs}_ {i} = \ f rac {1 }{ 2}(\m athc al {F}_{A}(\mathbb {P}, \mathbb {F}, \Lambda (\mathbb {F}), \mathbf {MV}_{i}, \mathbf {P}_i) + \mathcal {F}_{A'}(\mathbb {P}, \mathbb {F}, \Lambda (\mathbb {F}), \mathbf {MV}_{i}, \mathbf {P}_i)).
In Figure 10, we illustrate rendered images from FA and FA′.
Fig. 11:
FB
uses
tessellation
structure
to
efficiently
render
overlapped faces in the correct
order.
Acknowledging that this formulation is not
theoretically correct, we believe that it is an
intriguing future work to implement a fully
differentiable renderer that works for our case.
However, we empirically found out that we
can reconstruct a wide variety of meshes with
current formulation without much difficulty.
As mentioned before, this renderer is used
at the first phase of the optimization process,
where all of the point attributes are updated.
However, in the second phase, we fix the point
positions and weights, and only update point-
wise real values (Appendix 9.2). In this case,
we can leverage the tessellation structure to
implement an efficient differentiable renderer.
As the second renderer does a precise depth
testing unlike the first one, it can be used to modify the errors incurred by the
second limitation of the first renderer (Figure 12).


28
S. Son et al.
FB The second renderer performs precise depth ordering in an efficient way,
based on the fixed tessellation structure that we have. In Figure 11, we illustrate
a 2D diagram that explains our approach. When the green ray, which corre-
sponds to a single ray to determine the color of a single pixel, goes through the
tessellation, we can observe that it goes through a sequence of triangles (tetrahe-
dron in 3D), which are denoted as T1, T2, and T3. When the ray enters a triangle
Ti through one of its three edges, we can see that it moves onto the other adja-
cent triangle Ti+1 only through one of the other edges of Ti, because of compact
tessellation. Therefore, when the ray hits one edge of Ti, it can only examine
the other two edges of Ti to find the next edge it hits. Note that we do not have
to do depth testing explicitly in this approach. Also, unlike the first approach,
this renderer does not have to store all the possible faces that a ray collides for
the backward pass, because it can iterate the same process in the opposite way
in the backward pass to find the edge that it hit before the last edge. If we only
store the last edge that each hits at the forward pass, we can start from the last
edge and find the previous edges that it hit to compute gradients. Therefore, this
second renderer requires much less memory than the first one, and also performs
precise depth testing naturally. However, note that this renderer is also partilly
differentiable, because it cannot update point positions and weights.
To sum up, we implemented two partially differentiable renderers to solve
multi-view reconstruction problem with DMesh. They serve different objectives
in our reconstruction process, and we empirically found out that they are power-
ful enough to reconstruct target meshes in our experiments. However, we expect
that we can simplify the process and improve its stability, if we can implement a
fully differentiable renderer that satisfy our needs. We leave it as a future work.
8.4
Weight Regularization
Weight regularization aims at reducing the complexity of WDT, which supports
our mesh. By using this regularization, we can discard unnecessary points that
do not contribute to representing our mesh. Moreover, we can reduce the num-
ber of points on the mesh, if they are redundant, which ends up in the mesh
simplification effect (Appendix 10.3).
We formulate the complexity of WDT as the sum of edge lengths in its dual
Power diagram. Formally, we can write the regularization as follows,
 wL_{we i
g
ht} = \su
m _{i=1, ..., N} Length(E_{i}),
where Ei are the edges in the dual Power diagram, and N is the number of edges.
8.5
Real Regularization
Real regularization is a regularization that is used for maintaining the real val-
ues of the connected points in WDT as similar as possible. Also, we leverage
this regularization to make real values of points that are connected to the points


DMesh: A Differentiable Representation for General Meshes
29
with high real values to become higher, so that they can be considered in recon-
struction more often than the points that are not connected to those points. To
be specific, note that we ignore faces with very low existence probability in the
reconstruction process. By using this regularization, it can remove holes more
effectively.
This real regularzation can be described as
  L_{ r
e
a
l} &= \fr ac {1
}
{\sum _{i
=1,.. . ,N}\Lam b da (F_i)
}\sum _ {
i
=
1,...,N
} \ L amb d a ( F_i
)
\c
dot (\ s i
g
m
a _{1}(
F_ i ) +  \s igm
a _{2}(F_i) ) , \\ \sigma _{1}(F_i) &= \frac {1}{3}\sum _{j=1,2,3} | \psi _{j} - \frac {(\psi _{1} + \psi _{2} + \psi _{3})}{3} |, \\ \sigma _{1}(F_i) &= \frac {1}{3}\sum _{j=1,2,3} | 1 - \psi _{j} | \cdot \mathbb {I}(\max _{j=1, 2, 3}(\psi _{j}) > \delta _{high}).
Here ψ1,2,3 represent the real values of points that comprise Fi, and δhigh is a
threshold to determine “high” real value, which is set as 0.8 in our experiments.
Note that the faces with higher existence probabilities are prioritized over the
others.
8.6
Quality Regularization
After reconstruction, we usually want to have a mesh that is comprised of trian-
gles of good quality, rather than ill-formed triangles. We adopt the aspect ratio
as a quality measure for the triangular faces, and minimize the sum of aspect
ratios for all faces during optimization to get a mesh of good quality. Therefore,
we can write the regularization as follows.
  L_{ q
u
a
l} &= \fr ac {1
}
{\sum _{i
=1,... , N}\Lambd a  (F_i)
}\sum _ {i=1,...
,N} AR(F _
i
)
 \
cdot E_{ m ax}(F_i ) \c dot \L am bda
 (F_i), \ \ AR(F_ i) &= \f rac {E_{max}(F_i)}{H_{min}(F_i)} \cdot \frac {\sqrt {3}}{2},\\ E_{max}(F_i) &= \text {Maximum edge length of $F_i$},\\ H_{min}(F_i) &= \text {Minimum height of $F_i$}.\\
Note that we prioritize faces with larger maximum edge length and higher
existence probability than the others in this formulation. In Appendix 10.3, we
provide ablation studies for this regularization.
9
Optimization Process
In this section, we explain the optimization processes, or exact reconstruction
algorithms, in detail. First, we discuss the optimization process for the exper-
iment in Section 4.1, where we represent the ground truth mesh with DMesh.


30
S. Son et al.
Algorithm 1 Mesh to DMesh
Pgt, Fgt ←Ground truth mesh vertices and faces
P, W, ψ ←Initialize point attributes for DMesh
¯
F ←Empty set of faces
while Optimization not ended do
P, W, ψ ←Do point insertion, with P, ¯
F
WDT, PD ←Run WDT algorithm, with P, W
¯
F ←Update faces to exclude, with WDT
Λ(Fgt), Λ(¯
F) ←Compute existence probability for faces, with P, ψ, WDT, PD
Lrecon ←Compute reconstruction loss, with Λ(Fgt), Λ(¯
F)
Update P, W, ψ to minimize Lrecon
Bound P
end
M ←Get final mesh from DMesh
Then, we discuss the overall optimization process for point cloud or multi-view
reconstruction tasks in Section 4.2, from initialization to post processing.
9.1
Mesh to DMesh
Our overall algorithm to convert the ground truth mesh into DMesh is outlined
in Algorithm 1. We explain each step in detail below.
Point Initialization At the start of optimization, we initialize the point po-
sitions (P), weights (W), and real values (ψ) using the given ground truth in-
formation (Pgt, Fgt). To be specific, we initialize the point attributes as follows.
  \mat
h b b { P} =  \m
a t hbb  {P} _{gt}, \quad \mathbb {W} = [ 1, ..., 1], \quad \mathbb {\psi } = [1, ..., 1].
The length of vector W and ψ is equal to the number of points. In Figure 13,
we illustrate the initialized DMesh using these point attributes, which becomes
the convex hull of the ground truth mesh.
Note that during optimization, we allow only small perturbations to the
positions of initial points, and fix weights and real values of them to 1. This is
because we already know that these points correspond to the ground truth mesh
vertices, and thus should be included in the final mesh without much positional
difference. In our experiments, we set the perturbation bound as 1% of the model
size.
However, we notice that we cannot restore the mesh connectivity with only
small perturbations to the initial point positions, if there are no additional points
that can aid the process. Therefore, we periodically perform point insertion to
add additional points, which is described below.
Point Insertion The point insertion is a subroutine to add additional points
to the current point configurations. It is performed periodically, at every fixed


DMesh: A Differentiable Representation for General Meshes
31
(a) Ground Truth
(b) Initialization
(c) Point Insertion
(d) 5000 Steps
Fig. 13: Intermediate results in converting bunny model to DMesh. For given
ground truth mesh in (a), we initialize our point attributes using the mesh vertices.
(b) Then, the initial mesh becomes convex hull of the original mesh. (c) To remove
undesirable faces that were not in the original mesh, we insert additional points on the
undesirable faces. Then, some of them disappear because of the inserted points. (d)
After optimizing 5000 steps, just before another point insertion, DMesh recovers most
of the ground truth connectivity.
step. The additional points are placed at the random place on the faces in ¯
F,
which correspond to the faces that should not exist in the final mesh. Therefore,
these additional points can aid removing these undesirable faces.
However, we found out that inserting a point for every face in ¯
F can be
quite expensive. Therefore, we use k-means clustering algorithm to aggregate
them into 0.1 · NF clusters, where NF is the number of faces in ¯
F, to add the
centroids of the clusters to our running point set. On top of that, we select 1000
random faces in ¯
F to put additional points directly on them. This is because
there are cases where centroids are not placed on the good positions where they
can remove the undesirable faces.
In Figure 13, we render DMesh after point insertion to the initialized mesh.
Note that some of the undesirable faces disappear because of the added points.
Maintaining ¯
F In this problem, we minimize the reconstruction loss specified
in Eq. 11 to restore the connectivity in the ground truth mesh, and remove
faces that do not exist in it. In the formulation, we denoted the faces that are
comprised of mesh vertices P, but are not included in the original mesh as ¯
F.
Even though we can enumerate all of them, the total number of faces in ¯
F
mounts to O(N 3), where N is the number of mesh vertices. Therefore, rather
than evaluating all of those cases, we maintain a set of faces ¯
F that we should
exclude in our mesh during optimization.
To be specific, at each iteration, we find faces in the current WDT that are
comprised of points in P, but do not exist in F, and add them to the running set
of faces ¯
F. On top of that, at every pre-defined number of iterations, in our case
10 steps, we compute k-nearest neighboring points for each point in P. Then, we
find faces that can be generated by combining each point with 2 of its k-nearest
points, following [42]. Then, we add the face combinations that do not belong to
F to ¯
F. In our experiments, we set k = 8.


32
S. Son et al.
Algorithm 2 Point cloud & Multi-view Reconstruction
T ←Observation (Point cloud, Multi-view images)
P, W, ψ ←Initialize point attributes for DMesh (using T if possible)
F ←Empty set of faces
while epoch not ended do
P, W, ψ ←(If not first epoch) Initialize point attributes with sample points from
current DMesh, for mesh refinement
// Phase 1
while step not ended do
WDT, PD ←Run WDT algorithm with P, W
F ←Update faces to evaluate existence probability for, with WDT
Λ(F) ←Compute existence probability for faces in F, with P, ψ, WDT, PD
Lrecon ←Compute reconstruction loss, with P, F, Λ(F), T
Lweight ←Compute weight regularization, with PD
Lreal ←Compute real regularization, with P, ψ, WDT
Lqual ←Compute quality regularization, with P, F, Λ(F)
L ←Lrecon + λweight · Lweight + λreal · Lreal + λqual · Lqual
Update P, W, ψ to minimize L
end
// Phase 2
WDT, PD ←Run WDT algorithm with P, W
F ←Faces in WDT
Λwdt(F) ←1
while step not ended do
Λ(F) ←Compute existence probability for F, with P, ψ, Λwdt(F)
Lrecon ←Compute reconstruction loss, with P, F, Λ(F), T
Lreal ←Compute real regularization, with P, ψ, WDT
L ←Lrecon + λreal · Lreal
Update ψ to minimize L
end
end
M ←Get final mesh from DMesh, after post-processing
9.2
Point cloud & Multi-view Reconstruction
In Algorithm 2, we describe the overall algorithm that is used for point cloud
and multi-view reconstruction tasks. We explain each step in detail below.
Two Phase Optimization We divide each optimization epoch in two phases.
In the first phase (phase 1), we optimize all of the point attributes – positions,
weights, and real values. However, in the second phase (phase 2), we fix the point
positions and weights, and only optimize the real values.
This design aims at removing ambiguity in our differentiable formulation.
That is, even though we desire face existence probabilities to converge to either
0 and 1, those probabilities can converge to the values in between. To alleviate
this ambiguity, after the first phase ends, we fix the tessellation to make Λwdt
for each face in F to either 0 or 1. Therefore, in the second phase, we only care


DMesh: A Differentiable Representation for General Meshes
33
(a) Ground Truth
(b) Initialized DMesh (Points, Extracted Mesh)
Fig. 14: Initialized DMesh using sample points from ground truth mesh. (a)
From ground truth mesh, we uniformly sample 10K points to initialize DMesh. (b) In
the left figure, sample points from the ground truth mesh (Psample) are rendered in
red. The points that correspond to Pvoronoi are rendered in blue. In the right figure,
we render the initial mesh we can get from the points, which has a lot of holes.
about the faces that exist in current WDT, which have Λwdt value of 1. Then,
we can only care about real values.
Note that the two differentiable renderers that we introduced in Appendix 8.3
are designed to serve for these two phases, respectively.
Point Initialization with Sample Points In this work, we propose two point
initialization methods. The first initialization method can be used when we have
sample points near the target geometry in hand.
This initialization method is based on an observation that the vertices of
Voronoi diagram of a point set tend to lie on the medial axis of the target
geometry [1,2]. Therefore, for the given sample point set Psample, we first build
Voronoi diagram of it, and find Voronoi vertices Pvoronoi. Then, we merge them
to initialize our point set P:
  \mathbb  {P} = \mathbb {P}_{sample} \cup \mathbb {P}_{voronoi}, 
all of which weights are initialized to 1. Then, we set the real values (ψ) of points
in Psample as 1, while setting those of points in Pvoronoi as 0.
In Figure 14, we render the mesh that we can get from this initialization
method, when we use 10K sample points. Note that the initial mesh has a lot
of holes, because there could be Voronoi vertices that are located near the mesh
surface, as pointed out by [2]. However, we can converge to the target mesh
faster than the initialization method that we discuss below, because most of the
points that we need are already located near the target geometry.
Point Initialization without Sample Points If there is no sample point
that we can use to initialize our points, we initialize our points with N 3 points
regularly distributed on a grid structure that encompasses the domain, all of


34
S. Son et al.
(a) Epoch 1, Initial State
(b) Epoch 1, Last State
(c) Epoch 2, Initial State
(d) Epoch 2, Last State
(e) Epoch 3, Initial State
(f) Epoch 3, Last State
(g) Epoch 4, Initial State
(h) Epoch 4, Last State
Fig. 15: Optimization process for multi-view reconstruction for Plant model.
At each row, we present the initial state (left) and the last state (right) of each epoch.
For each figure, the left rendering shows the point attributes color coded based on real
values, while the right one shows the extracted mesh. (a), (b) In the first epoch, we
initialize DMesh without sample points. At the end of each epoch, we sample points
from the current mesh, and use them for initialization in the next epoch.
which has weight 1 and ψ value of 1. We set N = 20 for every experiment
(Figure 15a). Then, we optimize the mesh to retrieve a coarse form of the target
geometry (Figure 15b). Note that we need to refine this mesh in the subsequent
epochs, as explained below.
Point Initialization for Different Inputs Until now, we introduced two point
initialization techniques. When the input is a point cloud, we sample subset of the
point cloud to initialize our mesh (Figure 14). However, when the input is multi-
view images, we start from initialization without sample points (Figure 15),
because there is no sample point cloud that we can make use of.


DMesh: A Differentiable Representation for General Meshes
35
Maintaining F We maintain the running set of faces to evaluate probability
existence for in F. At each iteration, after we get WDT, we insert every face in
WDT to F, as it has a high possibility to persist in the subsequent optimization
steps. Also, as we did int mesh to DMesh conversion (Appendix 9.1), at every
10 optimization step, we find k-nearest neighbors for each point, and form face
combinations based on them. Then, we add them to F.
Mesh Refinement At start of each epoch, if it is not the first epoch, we refine
our mesh by increasing the number of points. To elaborate, we refine our mesh
by sampling N number of points on the current DMesh, and then initialize
point attributes using those sample points as we explained above. We increase
N as number of epoch increases. For instance, in our multi-view reconstruction
experiments, we set the number of epochs as 4, and set N = (1K, 3K, 10K)
for the epochs excluding the first one. In Figure 15, we render the initial and
the last state of DMesh of each epoch. Note that the mesh complexity increases
and becomes more accurate as epoch proceeds, because we use more points.
Therefore, this approach can be regarded as a coarse-to-fine approach.
Post-Processing When it comes to multi-view reconstruction, we found out
that it is helpful to add one more constraint in defining the face existence. In our
formulation, in general, a face F has two tetrahedra (T1, T2) that are adjacent
to each other over the face. Then, we call the remaining point of T1 and T2 that
is not included in F as P1 and P2. Our new constraint requires at least one of
P1 and P2 to have ψ value of 0 to let F exist.
This additional constraint was inspired by the fact that F is not visible from
outside if F exists in our original formulation, and both of P1 and P2 have ψ value
of 1. That is, if it is not visible from outside, we do not recognize its existence.
This constraint was also adopted to accommodate our real regularization, which
increases the real value of points near surface. If this regularization makes the
real value of points inside the closed surface, they would end up in internal faces
that are invisible from outside. Because of this invisibility, our loss function
cannot generate a signal to remove them. In the end, we can expect all of the
faces inside a closed surface will exist, because of the absence of signal to remove
them. Therefore, we choose to remove those internal faces by applying this new
constraint in the post-processing step.
Note that this discussion is based on the assumption that our renderer does a
precise depth testing. If it does not do the accurate depth testing, internal faces
can be regarded as visible from outside, and thus get false gradient signal. In
Figure 12a, the final mesh after phase 1 is rendered, and we can see therer are
lots of internal faces as the renderer used in phase 1 does not support precise
depth testing. However, we can remove them with the other renderer in phase
2, as shown in Figure 12b, which justifies our implementation of two different
renderers.


36
S. Son et al.
Finally, we note that this constraint is not necessary for point cloud recon-
struction, because if we minimize CDours in Appendix 8.2, the internal faces
will be removed automatically.
10
Experimental Details
In this section, we provide experimental details for the results in Section 4, and
visual renderings of the our reconstructed mesh. Additionally, we provide the
results of ablation studies about regularizations that we suggested in Section 3.4.
10.1
Mesh to DMesh
As shown in Table 1, we reconstruct the ground truth connectivity of Bunny,
Dragon, and Buddha model from Stanford dataset [13]. For all these experiments,
we optimized for 20K steps, and used an ADAM optimizer [22] with learning
rate of 10−4. For Bunny model, we inserted additional points at every 5000 step.
For the other models, we inserted them at every 2000 step.
In Figure 16, we provide the ground truth mesh and our reconstructed mesh.
We can observe that most of the connectivity is preserved in our reconstruction,
as suggested numerically in Table 1. However, note that the appearance of the
reconstructed mesh can be slightly different from the ground truth mesh, because
we allow 1% of positional perturbations to the mesh vertices.
10.2
Point Cloud & Multi-view Reconstruction
Hyperparameters for Point Cloud Reconstruction
– Optimizer: ADAM Optimizer, Learning rate = 10−4 for open surface meshes
and two mixed surface meshes (Bigvegas, Raspberry) / 3 · 10−4 for closed
surface meshes, and one mixed surface mesh (Plant).
– Regularization: λweight = 10−8, λreal = 10−3, λqual = 10−3 for every mesh.
– Number of epochs: Single epoch for every mesh.
– Number of steps per epoch: 1000 steps for phase 1, 500 steps for phase 2 for
every mesh.
Hyperparameters for Multi-view Reconstruction
– Optimizer: ADAM Optimizer, Learning rate = 10−3 in the first epoch, and
3 · 10−4 in the other epochs for every mesh.
– Weight Regularization: λweight = 10−8 for every mesh.
– Real Regularization: λreal = 10−3 for the first 100 steps in every epoch for
open surface meshes and one mixed surface mesh (Plant) / 10−2 for the first
100 steps in every epoch for closed surface meshes and two mixed surface
meshes (Bigvegas, Raspberry).
– Quality Regularization: λqual = 10−3 for every mesh.


DMesh: A Differentiable Representation for General Meshes
37
(a) Ground Truth Mesh
(b) Reconstructed DMesh
Fig. 16: Reconstruction results for mesh to DMesh experiment. From Left:
Bunny, Dragon, and Buddha. We can observe that most of the edge connectivity is
perserved in the reconstruction, even though the appearance is slightly different from
the ground truth mesh because of small perturbations of vertex positions.
– Normal Coefficient: λnormal = 0 for every mesh (Eq. 13).
– Number of epochs: 4 epochs for every mesh. In the first epoch, use 20−3 reg-
ularly distributed points for initialization. In the subsequent epochs, sample
1K, 3K, and 10K points from the current mesh for initialization.
– Number of steps per epoch: 500 steps for phase 1, 500 steps for phase 2 for
every mesh.
– Batch size: 64 for open surface meshes, 16 for the other meshes.
Visual Renderings In Figure 21, 22, and 23, we provide visual renderings of
our point cloud and multi-view reconstruction results with ground truth mesh.
We also provide illustration of input point cloud and diffuse map. Note that we
also used depth renderings for multi-view reconstruction experiments.
Additional Discussion Generally, we can observe that reconstruction results
from both point cloud and multi-view images capture the overall topology well.
However, we noticed that the multi-view reconstruction results are not as good
as point cloud reconstruction results. In particular, we can observe small holes in
the multi-view reconstruction results. We assume that these artifacts are coming


38
S. Son et al.
(a) Ground Truth Mesh
(b) Flexicube
(c) Ours
Fig. 17: Reconstruction results for a closed surface model in Thingi32
dataset. Flexicube [44] can generate internal structures, while our approach removes
them through post-processing.
(a) Ground Truth
(b) Flexicube
(c)
Flexicube,
self-intersecting
faces removed
Fig. 18: Reconstruction results for the Plant model. Flexicube [44] can gener-
ate redundant, self-intersecting faces for open surfaces, in this case, leaves. To better
capture the redundant faces, we rendered the models from upper side, which is shown
in the bottom right figures.
from relatively weaker supervision of multi-view images than dense point clouds.
Also, we believe that we can improve these multi-view reconstruction results with
more advanced differentiable renderer, and better mesh refinement strategy. In
the current implementation, we lose connectivity information at the start of each
epoch, which is undesirable. We believe that we can improve this approach by
inserting points near the regions of interest, rather than resampling over entire
mesh.
Also, regarding comparison to Flexicube [44] in Table 2, we tried to found
out the reason why ours give better results than Flexicube in terms of CD to the
ground truth mesh for closed surfaces in thingi32 dataset. We could observe that
Flexicube’s reconstruction results capture fine geometric details on the surface
mesh, but also observed that they have lots of false internal structure (Fig-
ure 17). Note that this observation not only applies to closed surfaces, but also


DMesh: A Differentiable Representation for General Meshes
39
(a) Bigvegas
(b) Plant
Fig. 19: Point cloud reconstruction results with different λweight. From Left:
λweight = 10−6, 10−5, and 10−4.
to open surfaces, where it generates lots of false, self-intersecting faces (Fig-
ure 18). Our results do not suffer from these problems, as we do post-processing
(Appendix 9.2) to remove inner structure, and also our method can represent
open surfaces better than the volumetric approaches without self-intersecting
faces.
10.3
Ablation studies
In this section, we provide ablation studies for the regularizations that we pro-
posed in Section 3.4. We tested the effect of the regularizations on the point
cloud reconstruction task.
Weight Regularization We tested the influence of weight regularzation in the
final mesh, by choosing λweight in (10−6, 10−5, 10−4). Note that we set the other
experimental settings as same as described in Section 10.2, except λquality, which
is set as 0, to exclude it from optimization.
In Table 4, we provide the quantitative results for the experiments. For dif-
ferent λweight, we reconstructed mesh from point clouds, and computed average
Chamfer Distance (CD) and average number of faces across every test data. We
can observe that there exists a clear tradeoff between CD and mesh complexity.


40
S. Son et al.
(a) Bigvegas
(b) Plant
Fig. 20: Point cloud reconstruction results with different λquality. From Left:
λreal = 10−4, 10−3, and 10−2.
To be specific, when λweight = 10−6, the CD is not very different from the results
in Table 2, where we use λweight = 10−8. However, when it increases to 10−5 and
10−4, we can observe that the mesh complexity (in terms of number of faces)
decreases, but CD increases quickly.
Table
4:
Ablation
study
for
weight regularization, quantitative
results.
λweight
10−6 10−5 10−4
CD
7.48 8.08 10.82
Num. Face 4753 2809 1786
The renderings in Figure 19 support these
quantitative results. When λweight = 10−6,
we can observe good reconstruction quality.
When λweight = 10−5, there are small arti-
facts in the reconstruction, but we can get
meshes of generally good quality with fewer
number of faces. However, when it becomes
10−4, the reconstruction results deteriorate,
making holes and bumpy faces on the smooth surface. Therefore, we can con-
clude that weight regularization contributes to reducing the mesh complexity.
However, we need to choose λweight carefully, so that it does not harm the recon-
struction quality. The experimental results tell us setting λweight to 10−6 could
be a good choice to balance between these two contradictory objectives.
Quality Regularization As we did in the previous section, we test the in-
fluence of quality regularization in the final mesh by selecting λreal among


DMesh: A Differentiable Representation for General Meshes
41
(10−4, 10−3, 10−2). We also set the other experimental settings as same as before,
except λweight = 0.
Table 5: Ablation study for qual-
ity regularization, quantitative re-
sults.
λqual
10−4 10−3 10−2
CD
7.60 7.42 7.28
Num. Face
8266 8349 10806
Aspect Ratio 2.33 2.06 1.55
In Table 5 and Figure 20, we present quan-
titative and qualitative comparisons between
the reconstruction results. We provide statis-
tics about average CD, average number of
faces, and average aspect ratio of faces. In-
terestingly, unlike weight regularization, we
could not observe tradeoff between CD and
aspect ratio. Rather than that, we could find
that CD decreases as aspect ratio gets smaller,
and thus the triangle quality gets better.
We find the reason for this phenomenon in the increase of smaller, good
quality triangle faces. Note that there is no significant difference between the
number of faces between λqual = 10−4 and 10−3. Also, we cannot find big dif-
ference between visual renderings between them, even though the aspect ratio
was clearly improved. However, when λqual becomes 10−2, the number of faces
increase fast, which can be observed in the renderings, too. We believe that this
increase stems from our quality constraint, because it has to generate more tri-
angles to represent the same area, if there is less degree of freedom to change the
triangle shape. Since it has more triangle faces, we assume that they contribute
to capturing fine details better, leading to the improved CD.
However, at the same time, note that the number of holes increase as we
increase λqual, which lead to visual artifacts. We assume that there are not
enough points to remove these holes, by generating quality triangle faces that
meet our needs. Therefore, as discussed before, if we can find a systematic way to
prevent holes, or come up with a better optimization scheme to remove them, we
expect that we would be able to get accurate mesh comprised of better quality
triangles.


42
S. Son et al.
(a) Mesh 164
(b) Mesh 30
(c) Mesh 320
(d) Mesh 448
Fig. 21: Point cloud and Multi-view Reconstruction results for open surface
models. From Left: Ground truth mesh, sample point cloud, point cloud reconstruction
results, diffuse rendering, multi-view reconstruction results.


DMesh: A Differentiable Representation for General Meshes
43
(a) Mesh 64444
(b) Mesh 252119
(c) Mesh 313444
(d) Mesh 527631
Fig. 22: Point cloud and Multi-view Reconstruction results for closed surface
models. From Left: Ground truth mesh, sample point cloud, point cloud reconstruction
results, diffuse rendering, multi-view reconstruction results.


44
S. Son et al.
(a) Bigvegas
(b) Plant
(c) Mesh 313444
Fig. 23: Point cloud and Multi-view Reconstruction results for mixed sur-
face models. From Left: Ground truth mesh, sample point cloud, point cloud recon-
struction results, diffuse rendering, multi-view reconstruction results.